# X-ray Grad-CAM 포트폴리오

> 이 문서는 면접 대비 및 포트폴리오 제출용입니다.

---

## 1. 프로젝트 한 줄 요약

**"딥러닝 폐렴 분류 모델의 예측 결과를 Grad-CAM으로 시각화하여 의료진의 판단 근거를 해석 가능하게 만든 웹 데모"**

---

## 2. 시스템 아키텍처 (모듈 분리 설계)

```
┌─────────────────────────────────────────────────────────────────────────┐
│                        HuggingFace Spaces                               │
│                                                                         │
│  ┌──────────────┐     ┌──────────────┐     ┌──────────────┐            │
│  │  사용자 업로드 │────▶│   main.py    │────▶│  결과 시각화  │            │
│  │ DICOM/PNG/JPG│     │ (UI 전담)    │     │ Grad-CAM     │            │
│  └──────────────┘     └──────┬───────┘     └──────────────┘            │
│                              │                                         │
│              ┌───────────────┼───────────────┐                        │
│              ▼               ▼               ▼                        │
│       ┌──────────┐    ┌──────────┐    ┌──────────┐                   │
│       │config.py │    │styles.py │    │grandcam_ │                   │
│       │ (설정)   │    │ (CSS)    │    │ core.py  │                   │
│       └──────────┘    └──────────┘    └────┬─────┘                   │
│              │                             │                          │
│              └─────────────────────────────┘                          │
│                              │                                         │
│              ┌───────────────┼───────────────┐                        │
│              ▼               ▼               ▼                        │
│       ┌──────────┐    ┌──────────┐    ┌──────────┐                   │
│       │ ResNet18 │    │EfficientNet│   │DenseNet121│                  │
│       │ (0.25)   │    │  (0.15)  │    │  (0.18)  │                   │
│       └──────────┘    └──────────┘    └──────────┘                   │
│                              │                                         │
│                       ┌──────────────┐                                 │
│                       │  체크포인트   │                                 │
│                       │ (Git LFS)    │                                 │
│                       └──────────────┘                                 │
└─────────────────────────────────────────────────────────────────────────┘
```

### 모듈 분리 구조

| 모듈 | 역할 | 확장 포인트 |
|------|------|-------------|
| `config.py` | 설정 중앙 관리 | 모델 추가 시 `MODEL_CONFIG`에 항목 추가만 |
| `styles.py` | CSS 테마 관리 | 새 테마(Light 등) 추가 가능 |
| `grandcam_core.py` | Grad-CAM 로직 | FastAPI 등 다른 프레임워크에서 재사용 |
| `main.py` | Streamlit UI | UI 변경 시 이 파일만 수정 |

### 면접 질문: "시스템 구조를 설명해주세요"
**답변**:
- **모듈 분리 설계**: UI(main.py), 로직(grandcam_core.py), 설정(config.py), 스타일(styles.py)
- Streamlit 기반 웹 앱으로 HuggingFace Spaces에 배포
- 사용자가 DICOM/PNG/JPEG 흉부 X-ray 업로드
- 3개 모델(ResNet18, EfficientNet-B0, DenseNet121)로 폐렴 분류
- Grad-CAM으로 모델이 주목한 영역을 히트맵으로 시각화
- **확장성**: config.py 수정만으로 새 모델 추가 가능

---

## 3. 핵심 모듈 4개 (반드시 숙지)

### 3.1 config.py (설정 중앙 관리)

**역할**: 프로젝트 전역 설정 중앙화

**주요 구성**:
| 구성 요소 | 역할 |
|-----------|------|
| `MODEL_CONFIG` | 모델별 builder, checkpoint, target_layer, input_size |
| `BEST_THRESHOLDS` | 모델별 최적 threshold (ROC 분석 기반) |
| `DICOM_*` 상수 | DICOM 전처리 파라미터 |
| `NORMALIZE_*` | ImageNet 정규화 설정 |

**핵심 코드 - 모델 설정**:
```python
MODEL_CONFIG: Dict[str, Dict[str, Any]] = {
    "ResNet18": {
        "builder": models.resnet18,
        "checkpoint": "checkpoints/251115_resnet18_NP.pth",
        "target_layer": "layer4",
        "input_size": 224,
    },
    # 새 모델 추가 시 여기에 항목만 추가
}

BEST_THRESHOLDS: Dict[str, float] = {
    "ResNet18": 0.25,
    "EfficientNet-B0": 0.15,
    "DenseNet121": 0.18,
}
```

**확장 포인트**: 새 모델 추가 시 이 파일만 수정

### 3.2 styles.py (CSS 스타일 관리)

**역할**: UI 테마 분리 관리

**주요 구성**:
| 구성 요소 | 역할 |
|-----------|------|
| `DARK_CSS` | 다크 테마 + X-ray 스타일 |
| `get_css()` | 테마별 CSS 반환 함수 |

**확장 포인트**: Light 테마 등 새 테마 추가 가능

### 3.3 grandcam_core.py (비즈니스 로직)

**역할**: Grad-CAM 계산 로직 (API 서버 등에서 재사용 가능)

**주요 함수**:
| 함수명 | 역할 |
|--------|------|
| `dicom_to_pil()` | DICOM 바이트 → PIL 변환 |
| `image_bytes_to_pil()` | PNG/JPEG → PIL 변환 |
| `GradCAM` 클래스 | Grad-CAM 계산 (forward/backward hook) |
| `get_model_bundle()` | 모델 로드 + 캐싱 |
| `run_gradcam_on_pil()` | 단일 모델 Grad-CAM 실행 |
| `run_gradcam_all_models()` | 3개 모델 일괄 실행 |
| `get_available_models()` | 사용 가능한 모델 목록 반환 |

**핵심 코드 - DICOM 전처리**:
```python
def dicom_to_pil(file_bytes: bytes):
    dcm = pydicom.dcmread(io.BytesIO(file_bytes))
    img = dcm.pixel_array.astype(np.float32)

    # HU 변환 (원본 픽셀 → 실제 CT 값)
    if hasattr(dcm, "RescaleSlope") and hasattr(dcm, "RescaleIntercept"):
        img = img * slope + intercept

    # Lung window 적용 (config.py 설정값 사용)
    min_val = DICOM_WINDOW_CENTER - DICOM_WINDOW_WIDTH / 2.0
    max_val = DICOM_WINDOW_CENTER + DICOM_WINDOW_WIDTH / 2.0
```

**핵심 코드 - Grad-CAM 계산**:
```python
class GradCAM:
    def __call__(self, x, target_class=None, threshold=0.5):
        logits = self.model(x)

        # 이진 분류: sigmoid → threshold로 분류
        prob_pos = torch.sigmoid(logits)[0, 0]
        target_class = int((prob_pos >= threshold).item())

        # backward로 gradient 계산
        score.backward(retain_graph=True)

        # CAM = 채널별 가중치 * activation
        weights = grad.mean(dim=(2, 3), keepdim=True)
        cam = (weights * act).sum(dim=1, keepdim=True)
        cam = F.relu(cam)  # 음수 제거
```

### 3.4 main.py (UI 전담)

**역할**: Streamlit 웹 UI만 담당

**주요 구성**:
| 구성 요소 | 역할 |
|-----------|------|
| 탭 구성 | Grad-CAM 시각화 / 예측 결과 / 이미지 정보 |
| 사이드바 | 이미지 업로드, 모델 선택, 옵션 |
| 결과 시각화 | 단일 모델 / 3개 모델 비교 모드 |

**설계 의도**:
- main.py는 UI만 담당
- 로직은 grandcam_core.py에서 import
- 설정은 config.py에서 import
- 스타일은 styles.py에서 import

---

## 4. 모델 설정 (외워야 함)

### 모델별 구성
| 모델 | Target Layer | Best Threshold | 비고 |
|------|-------------|----------------|------|
| ResNet18 | layer4 | 0.25 | 기본 CNN, 빠른 추론 |
| EfficientNet-B0 | features | 0.15 | 효율적 구조, 낮은 threshold |
| DenseNet121 | features | 0.18 | Dense 연결, 특징 재사용 |

### 면접 질문: "왜 모델마다 threshold가 다른가요?"
**답변**:
1. 각 모델의 학습 결과에서 ROC 분석으로 최적 threshold 도출
2. threshold가 낮을수록 폐렴에 민감 (Recall 높음)
3. 의료 진단 특성상 폐렴 놓치는 것보다 오탐이 나은 경우가 많음
4. EfficientNet이 가장 낮은 threshold → 가장 민감하게 설정

### 면접 질문: "Grad-CAM의 target layer를 왜 layer4/features로 선택했나요?"
**답변**:
1. 마지막 convolutional layer가 가장 고수준 특징 보유
2. ResNet18: layer4가 최종 conv block
3. EfficientNet/DenseNet: features가 전체 backbone
4. 너무 앞 layer는 저수준 특징(엣지, 텍스처)만 포착

---

## 5. 핵심 설계 결정 (면접 필수)

### Q1: DICOM Lung window (center=40, width=800) 이유?
**답변**:
- 학습 시 사용한 전처리와 동일해야 성능 보존
- center=40: 폐 조직의 대표적 HU 값
- width=800: 폐 내 다양한 밀도 표현 (-360 ~ 440 HU)
- 다른 window 사용 시 모델 성능 저하

### Q2: 출력을 1개 로짓으로 설계한 이유?
**답변**:
- 이진 분류(Normal/Pneumonia)에서 1개 로짓이 더 효율적
- sigmoid 적용으로 확률 해석 가능
- 2개 출력보다 파라미터 절약
- threshold 조절로 민감도/특이도 trade-off 가능

### Q3: Streamlit + HuggingFace Spaces 선택 이유?
**답변**:
- Streamlit: 빠른 프로토타이핑, Python만으로 웹 앱
- HuggingFace Spaces: 무료 GPU, 자동 배포, ML 커뮤니티
- GitHub Actions로 자동 동기화 구현

### Q4: 왜 4개 모듈로 분리했나요?
**답변**:
- **관심사 분리 (SoC)**: UI, 로직, 설정, 스타일 각각 독립
- **확장성**: config.py만 수정하면 새 모델 추가 가능
- **재사용성**: grandcam_core.py를 FastAPI 등에서 재사용 가능
- **테스트 용이성**: 각 모듈 독립적 테스트 가능
- **유지보수성**: 변경 시 해당 모듈만 수정

### Q5: 새 모델을 추가하려면 어떻게 하나요?
**답변**:
1. `config.py`의 `MODEL_CONFIG`에 항목 추가
2. `config.py`의 `BEST_THRESHOLDS`에 threshold 추가
3. 체크포인트 파일을 `checkpoints/`에 배치
4. **끝** - main.py, grandcam_core.py 수정 불필요

---

## 6. 기술 스택 정리

| 분류 | 기술 | 용도 |
|------|------|------|
| 언어 | Python 3.x | 전체 |
| 웹 프레임워크 | Streamlit 1.51.0 | UI |
| 딥러닝 | PyTorch, torchvision | 모델 추론 |
| 영상처리 | OpenCV, Pillow | 이미지 변환 |
| 의료영상 | pydicom | DICOM 파싱 |
| 배포 | HuggingFace Spaces | 호스팅 |
| CI/CD | GitHub Actions | 자동 배포 |
| 버전관리 | Git LFS | 대용량 체크포인트 |

---

## 7. 의료영상 도메인 지식 (차별화 포인트)

### DICOM 전처리 파이프라인
```
원본 픽셀 → HU 변환 → Windowing → 정규화 → RGB 변환
   ↓           ↓           ↓          ↓         ↓
 정수값    물리적 단위   관심영역   0~1 스케일  3채널
           (CT 밀도)    강조
```

### HU (Hounsfield Unit) 이해
| 조직 | HU 값 |
|------|-------|
| 공기 | -1000 |
| 폐 | -500 ~ -900 |
| 물/혈액 | 0 |
| 연조직 | 40~80 |
| 뼈 | 400~1000 |

### 면접 질문: "의료영상 처리 경험이 있나요?"
**답변**:
1. 방사선사 면허 보유 (의료영상 도메인 지식)
2. DICOM 포맷 이해 (메타데이터, 픽셀 데이터 구조)
3. HU 변환 및 Windowing 개념 숙지
4. Grad-CAM으로 모델 해석 가능성 구현

---

## 8. 에러 처리 패턴

### 패턴 1: 체크포인트 로딩 호환성
```python
# PyTorch 버전별 호환성 처리
try:
    ckpt = torch.load(ckpt_path, map_location=DEVICE, weights_only=False)
except TypeError:
    ckpt = torch.load(ckpt_path, map_location=DEVICE)
```

### 패턴 2: 다양한 체크포인트 포맷 대응
```python
if isinstance(ckpt, dict) and "model_state_dict" in ckpt:
    state_dict = ckpt["model_state_dict"]
elif isinstance(ckpt, dict) and "state_dict" in ckpt:
    state_dict = ckpt["state_dict"]
else:
    state_dict = ckpt  # 순수 state_dict
```

### 패턴 3: 선택적 의존성
```python
try:
    import pydicom
except ImportError:
    pydicom = None  # DICOM 없는 환경에서도 동작
```

---

## 9. 빠른 복습 체크리스트

- [ ] 시스템 아키텍처 그림 그릴 수 있는가?
- [ ] 4개 모듈 역할과 분리 이유 설명 가능한가?
- [ ] Grad-CAM 동작 원리 설명 가능한가?
- [ ] 3개 모델의 target layer와 threshold 외웠는가?
- [ ] DICOM Lung window 파라미터 외웠는가?
- [ ] HU 변환 개념 설명 가능한가?
- [ ] 새 모델 추가 방법 설명 가능한가?

---

## 10. 면접 1분 자기소개 예시

"저는 **의료영상 분야에 관심이 많은 개발자**입니다.

최근 개인 프로젝트로 **X-ray Grad-CAM Explorer**를 구축했습니다.
- **3개 딥러닝 모델**(ResNet18, EfficientNet, DenseNet)로 폐렴 분류
- **Grad-CAM**으로 모델이 주목한 영역을 시각화
- **DICOM 전처리** 파이프라인 구현 (HU 변환, Windowing)
- **모듈 분리 설계**로 확장성 확보 (config.py만 수정하면 새 모델 추가)
- **HuggingFace Spaces**에 배포, **GitHub Actions**로 자동 동기화

방사선사 면허를 보유하고 있어 **의료영상 도메인 지식**을 갖추고 있으며, 이를 활용해 해석 가능한 AI 시스템을 구현했습니다."

---

## 11. GitHub / 데모 링크

- **GitHub**: https://github.com/Z-3000/open_cv_grand
- **HuggingFace Demo**: https://huggingface.co/spaces/JH3907/xraygradcam
