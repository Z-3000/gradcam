# X-ray Grad-CAM 프로젝트 학습 자료 (면접 대비)

> 이 문서를 읽으면 프로젝트 전체를 15분 안에 파악할 수 있습니다.
> 각 섹션별로 "면접 예상 질문"과 "답변 포인트"를 포함했습니다.

---

## 1. 프로젝트 한 줄 요약

**"흉부 X-ray에서 폐렴을 분류하고, Grad-CAM으로 모델의 판단 근거를 시각화하는 Streamlit 웹앱"**

---

## 2. 시스템 아키텍처 (외워야 함)

```
┌─────────────────────────────────────────────────────────────┐
│                    HuggingFace Spaces                       │
│                                                             │
│  ┌──────────────┐     ┌──────────────┐     ┌──────────────┐│
│  │ 이미지 업로드 │────▶│   main.py    │────▶│ Grad-CAM    ││
│  │ DICOM/PNG/JPG│     │  (Streamlit) │     │  시각화      ││
│  └──────────────┘     └──────┬───────┘     └──────────────┘│
│                              │                              │
│                              ▼                              │
│                     ┌────────────────┐                      │
│                     │grandcam_core.py│                      │
│                     │ (비즈니스로직) │                      │
│                     └───────┬────────┘                      │
│                             │                               │
│         ┌───────────────────┼───────────────────┐          │
│         ▼                   ▼                   ▼          │
│   ┌──────────┐       ┌──────────┐       ┌──────────┐      │
│   │ ResNet18 │       │EfficientNet│      │DenseNet121│     │
│   │ (th=0.25)│       │ (th=0.15) │       │ (th=0.18) │     │
│   └──────────┘       └──────────┘       └──────────┘      │
└─────────────────────────────────────────────────────────────┘
         ▲
         │ 자동 배포
┌────────┴────────┐
│ GitHub Actions  │
│ (main push 시)  │
└─────────────────┘
```

### 면접 질문: "시스템 구조를 설명해주세요"
**답변**:
- Streamlit 기반 웹 애플리케이션으로, HuggingFace Spaces에 배포
- 사용자가 흉부 X-ray 이미지(DICOM/PNG/JPG)를 업로드
- 3개 CNN 모델(ResNet18, EfficientNet, DenseNet121)로 폐렴/정상 분류
- Grad-CAM으로 모델이 주목한 영역을 히트맵으로 시각화
- GitHub main 브랜치 push 시 Actions로 자동 배포

---

## 3. 핵심 모듈 4개 (반드시 숙지)

### 3.1 config.py (설정 중앙 관리)

**역할**: 모델 설정, threshold, DICOM 파라미터를 한 곳에서 관리

**주요 설정**:
| 설정 | 값 | 의미 |
|------|-----|------|
| `MODEL_CONFIG` | 3개 모델 정보 | builder, checkpoint 경로, target layer |
| `BEST_THRESHOLDS` | ResNet:0.25, EfficientNet:0.15, DenseNet:0.18 | ROC 기반 최적 임계값 |
| `DICOM_WINDOW_CENTER` | 40.0 | 폐 조직 대표 HU 값 |
| `DICOM_WINDOW_WIDTH` | 800.0 | 관찰 범위 (-360 ~ 440 HU) |

**핵심 코드 (38~64행)** - 모델 설정:
```python
MODEL_CONFIG: Dict[str, Dict[str, Any]] = {
    "ResNet18": {
        "builder": models.resnet18,
        "checkpoint": "checkpoints/251115_resnet18_NP.pth",
        "target_layer": "layer4",  # Grad-CAM 타겟 레이어
        "input_size": 224,
    },
    # EfficientNet, DenseNet도 동일 구조
}
```

### 면접 질문: "설정을 왜 별도 파일로 분리했나요?"
**답변**:
1. 유지보수성: 설정 변경 시 한 파일만 수정
2. 재사용성: 다른 프레임워크(FastAPI 등)에서도 동일 설정 사용
3. 확장성: 새 모델 추가 시 `MODEL_CONFIG`에 항목만 추가

---

### 3.2 grandcam_core.py (비즈니스 로직)

**역할**: Grad-CAM 계산, 모델 로딩, 이미지 전처리

**주요 함수**:
| 함수명 | 역할 |
|--------|------|
| `dicom_to_pil()` | DICOM → PIL Image 변환 (HU 변환 + Windowing) |
| `GradCAM` 클래스 | Grad-CAM 히트맵 계산 |
| `get_model_bundle()` | 모델 + target layer + transform 로드 (캐싱) |
| `run_gradcam_on_pil()` | 단일 모델 Grad-CAM 실행 |
| `run_gradcam_all_models()` | 3개 모델 Grad-CAM 실행 |

**핵심 코드 (122~223행)** - Grad-CAM 클래스:
```python
class GradCAM:
    """
    동작 원리:
    1. Forward pass: target layer의 activation 저장
    2. Backward pass: target class에 대한 gradient 저장
    3. CAM 계산: gradient의 global average → 채널별 가중치
                 가중치 * activation → 합산 → ReLU
    """
    def __init__(self, model, target_layer):
        # Forward hook: activation 저장
        def forward_hook(module, inputs, output):
            self.activations = output.detach()
            output.register_hook(self._save_gradients)
        self.target_layer.register_forward_hook(forward_hook)

    def __call__(self, x, target_class=None, threshold=0.5):
        # Forward → Backward → CAM 계산
        logits = self.model(x)
        score = logits[0, 0]
        score.backward(retain_graph=True)

        # Global average pooling → 채널별 가중치
        weights = self.gradients.mean(dim=(2, 3), keepdim=True)
        cam = (weights * self.activations).sum(dim=1, keepdim=True)
        cam = F.relu(cam)  # 음수 제거
        # 정규화 후 반환
```

### 면접 질문: "Grad-CAM이 무엇이고 어떻게 동작하나요?"
**답변**:
1. **정의**: 딥러닝 모델이 예측 시 어느 영역을 보고 판단했는지 시각화하는 기법
2. **동작 원리**:
   - Forward pass에서 마지막 Conv layer의 activation map 저장
   - Backward pass에서 예측 클래스에 대한 gradient 저장
   - Gradient를 global average pooling하여 채널별 중요도(가중치) 계산
   - 가중치와 activation map을 가중합 → ReLU → 히트맵
3. **의의**: 모델의 판단 근거를 해석 가능하게 만들어 의료 AI의 신뢰성 향상

---

### 3.3 styles.py (CSS 스타일)

**역할**: Streamlit 앱의 다크 테마 CSS 관리

**주요 스타일**:
- 다크 테마 배경 (X-ray 감성)
- 사이드바, 버튼, 탭 스타일링
- 확률 바, 히트맵 오버레이 스타일

### 면접 질문: "스타일을 왜 별도 파일로 분리했나요?"
**답변**:
1. 관심사 분리: UI 로직과 스타일 분리
2. 테마 확장: `get_css("dark")`, `get_css("light")` 형태로 테마 추가 가능
3. 코드 가독성: main.py에서 긴 CSS 문자열 제거

---

### 3.4 main.py (Streamlit UI)

**역할**: 사용자 인터페이스 (입력/출력/시각화)

**주요 구성**:
| 영역 | 역할 |
|------|------|
| 사이드바 | 이미지 업로드, 모델 선택, 옵션 설정 |
| 탭 1 | Grad-CAM 시각화 (원본 + 오버레이) |
| 탭 2 | 예측 결과 (클래스 확률 바) |
| 탭 3 | 이미지 메타데이터 (DICOM 정보) |

**핵심 코드 (131~156행)** - 단일 모델 시각화:
```python
with st.spinner(f"{model_name} Grad-CAM 계산 중..."):
    result = run_gradcam_on_pil(model_name, base_img, alpha)

col1, col2 = st.columns(2)
with col1:
    st.image(base_img, clamp=True)  # 원본
with col2:
    st.image(result["overlay"], clamp=True)  # Grad-CAM 오버레이

st.markdown(f"Predicted: {CLASS_NAMES[result['target_class']]} (p={result['target_prob']:.3f})")
```

---

## 4. 핵심 설계 결정 (면접 필수)

### Q1: 왜 이진 분류 출력을 1개 뉴런으로 했나요?
**답변**:
- 2클래스(Normal/Pneumonia) 분류인데 출력 1개 = Sigmoid(Pneumonia 확률)
- threshold 조정이 쉬움 (Recall 우선 시 threshold 낮춤)
- 의료 진단은 Recall 중요 (폐렴 놓치면 안 됨) → 낮은 threshold 사용

### Q2: 모델별 threshold가 다른 이유?
**답변**:
- 학습 후 ROC 곡선 분석하여 모델별 최적 threshold 도출
- ResNet18: 0.25, EfficientNet: 0.15, DenseNet: 0.18
- EfficientNet이 가장 민감 (낮은 threshold)

### Q3: DICOM Window Center/Width가 왜 40/800인가요?
**답변**:
- **Lung Window**: 폐 조직 관찰에 최적화된 HU 범위
- WC=40: 폐 조직의 대표 HU 값
- WW=800: 관찰 범위 (-360 ~ 440 HU)
- 학습 시 동일 파라미터 사용 → 추론 시에도 일관성 유지

### Q4: 왜 Streamlit을 선택했나요?
**답변**:
1. Python만으로 빠른 웹앱 개발 (프론트엔드 코드 불필요)
2. 데이터 과학/ML 시연에 최적화
3. HuggingFace Spaces에서 무료 호스팅 지원

### Q5: Git LFS를 왜 사용하나요?
**답변**:
- 모델 파일이 각각 ~89MB (총 ~267MB)
- GitHub 일반 파일 제한(100MB) 초과
- LFS로 대용량 파일을 별도 저장소에서 관리

---

## 5. 에러 처리 패턴

### 패턴 1: 선택적 의존성 (pydicom)
```python
try:
    import pydicom
except ImportError:
    pydicom = None  # DICOM 없는 환경에서도 PNG/JPG는 동작
```

### 패턴 2: PyTorch 버전 호환성
```python
try:
    ckpt = torch.load(path, map_location=DEVICE, weights_only=False)
except TypeError:
    ckpt = torch.load(path, map_location=DEVICE)  # 구버전 호환
```

### 패턴 3: 다양한 체크포인트 포맷 대응
```python
if isinstance(ckpt, dict) and "model_state_dict" in ckpt:
    state_dict = ckpt["model_state_dict"]
elif isinstance(ckpt, dict) and "state_dict" in ckpt:
    state_dict = ckpt["state_dict"]
else:
    state_dict = ckpt
```

---

## 6. 기술 스택 정리

| 분류 | 기술 | 용도 |
|------|------|------|
| 웹 프레임워크 | Streamlit 1.51.0 | 인터랙티브 UI |
| 딥러닝 | PyTorch, torchvision | 모델 추론 |
| 영상처리 | OpenCV, Pillow | 이미지 처리 |
| 의료영상 | pydicom | DICOM 파싱 |
| 배포 | HuggingFace Spaces | 호스팅 |
| CI/CD | GitHub Actions | 자동 배포 |
| 버전관리 | Git LFS | 대용량 파일 |

---

## 7. 빠른 복습 체크리스트

- [ ] 시스템 아키텍처 그림 그릴 수 있는가?
- [ ] 4개 모듈(config/core/styles/main) 역할 설명 가능한가?
- [ ] Grad-CAM 동작 원리 설명 가능한가?
- [ ] threshold가 모델별로 다른 이유 설명 가능한가?
- [ ] DICOM Window Center/Width 의미 설명 가능한가?
- [ ] 모듈 분리의 장점 설명 가능한가?

---

## 8. 면접 1분 자기소개 예시

"저는 **의료영상과 딥러닝**에 관심이 많은 개발자입니다.

최근 개인 프로젝트로 **X-ray Grad-CAM 시각화 웹앱**을 개발했습니다.
- 흉부 X-ray에서 **폐렴을 분류**하는 3개 CNN 모델 구현
- **Grad-CAM**으로 모델의 판단 근거 시각화
- **DICOM 전처리** (HU 변환, Lung Window) 적용
- **Streamlit + HuggingFace Spaces**로 배포
- **GitHub Actions**로 자동 배포 파이프라인 구축

이 과정에서 의료영상 전처리, 모델 해석 가능성(XAI), 모듈화 설계 경험을 쌓았습니다.

방사선사 면허와 의료영상 학사 배경을 바탕으로, 의료 AI 분야에서 기여하고 싶습니다."
