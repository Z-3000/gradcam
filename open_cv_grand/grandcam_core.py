# gradcam_core.py
"""
X-ray Grad-CAM ë°±ì—”ë“œ ëª¨ë“ˆ

- 3ê°œ ëª¨ë¸(ResNet18 / EfficientNet-B0 / DenseNet121) ë¡œë“œ
- DICOM/ì¼ë°˜ ì´ë¯¸ì§€ â†’ PIL â†’ Tensor ë³€í™˜
- Grad-CAM heatmap + overlay ìƒì„±
- ì¶”í›„ Streamlit / FastAPI ë“±ì—ì„œ ì¬ì‚¬ìš© ê°€ëŠ¥

ì£¼ì˜:
- .pth ì²´í¬í¬ì¸íŠ¸ì˜ êµ¬ì¡°(íŠ¹íˆ ì¶œë ¥ ì°¨ì›)ë¥¼ ì¡´ì¤‘í•˜ì—¬ ì„±ëŠ¥ì— ì˜í–¥ì„ ì£¼ì§€ ì•Šë„ë¡ ì„¤ê³„
- í˜„ì¬ ê°€ì •: í•™ìŠµ ë‹¹ì‹œ ìµœì¢… ì¶œë ¥ì´ 1ì°¨ì› (ë‹¨ì¼ ë¡œì§“, Pneumonia ì ìˆ˜)
"""

from __future__ import annotations
from typing import Tuple, Dict, Any, List, Optional

import io
import os

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models, transforms

import numpy as np
import cv2
from PIL import Image

try:
    # ê¸°ì¡´ DICOM ì „ì²˜ë¦¬ ëª¨ë“ˆì´ ìˆìœ¼ë©´ ì¬ì‚¬ìš© (í˜„ì¬ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
    from preprocess_core import dicom_to_pil as _dicom_to_pil_existing
    _HAS_PREPROCESS_CORE = True
except ImportError:
    _HAS_PREPROCESS_CORE = False

try:
    import pydicom  # type: ignore
except ImportError:
    pydicom = None  # DICOM ì—†ëŠ” í™˜ê²½ì—ì„œë„ import ì—ëŸ¬ ì•ˆ ë‚˜ê²Œ ì²˜ë¦¬

# ============================================================
# 0. ì „ì—­ ì„¤ì •
# ============================================================

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ì´ì§„ ë¶„ë¥˜ ê°€ì •: [Normal, Pneumonia]
NUM_CLASSES = 2
CLASS_NAMES = ["Normal", "Pneumonia"]

# ì‹¤ì œ .pth ìœ„ì¹˜ì— ë§ê²Œ checkpoint ê²½ë¡œë§Œ ë§ì¶”ë©´ ë¨
MODEL_CONFIG: Dict[str, Dict[str, Any]] = {
    "ResNet18": {
        "builder": models.resnet18,
        "checkpoint": "checkpoints/251115_resnet18_NP.pth",
        "target_layer": "layer4",
        "input_size": 224,
    },
    "EfficientNet-B0": {
        "builder": models.efficientnet_b0,
        "checkpoint": "checkpoints/251115_efficientnet_NP.pth",
        "target_layer": "features",
        "input_size": 224,
    },
    "DenseNet121": {
        "builder": models.densenet121,
        "checkpoint": "checkpoints/251115_densenet121_NP.pth",
        "target_layer": "features",
        "input_size": 224,
    },
}

# âœ… ëª¨ë¸ë³„ best_threshold (training_results.json ê¸°ë°˜)
BEST_THRESHOLDS: Dict[str, float] = {
    "ResNet18": 0.25,
    "EfficientNet-B0": 0.15,
    "DenseNet121": 0.18,
}


def get_best_threshold(model_name: str) -> float:
    """
    ëª¨ë¸ë³„ best_threshold ë°˜í™˜.
    ì •ì˜ë˜ì§€ ì•Šì€ ëª¨ë¸ì´ë©´ ê¸°ë³¸ê°’ 0.2 ì‚¬ìš©.
    """
    return BEST_THRESHOLDS.get(model_name, 0.2)

# ============================================================
# 1. DICOM / ì¼ë°˜ ì´ë¯¸ì§€ ë¡œë”©
# ============================================================

def dicom_to_pil(file_bytes: bytes) -> Tuple[Image.Image, Any]:
    """
    DICOM ë°”ì´íŠ¸ â†’ (PIL Image RGB, DICOM Dataset)

    í•™ìŠµ ì‹œ ì‚¬ìš©í•œ dicom_to_png(window_center=40, window_width=800)ì™€
    ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ HU ë³€í™˜ + ìœˆë„ìš° ì ìš© í›„ 0~255ë¡œ ìŠ¤ì¼€ì¼ë§.
    """
    if pydicom is None:
        raise ImportError("pydicom ì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. pip install pydicom í•„ìš”.")

    dcm = pydicom.dcmread(io.BytesIO(file_bytes))
    img = dcm.pixel_array.astype(np.float32)

    # 1) HU ë³€í™˜ (RescaleSlope, RescaleIntercept ì ìš©)
    if hasattr(dcm, "RescaleSlope") and hasattr(dcm, "RescaleIntercept"):
        slope = float(dcm.RescaleSlope)
        intercept = float(dcm.RescaleIntercept)
        img = img * slope + intercept

    # 2) Windowing (í•™ìŠµ ì‹œ ì‚¬ìš©í•œ íŒŒë¼ë¯¸í„°ì™€ ë™ì¼)
    window_center = 40.0
    window_width = 800.0
    min_val = window_center - window_width / 2.0
    max_val = window_center + window_width / 2.0

    img = (img - min_val) / (max_val - min_val)
    img = np.clip(img, 0.0, 1.0)
    img = (img * 255.0).astype(np.uint8)

    # 3) Grayscale â†’ RGB
    pil_img = Image.fromarray(img).convert("RGB")
    return pil_img, dcm


def image_bytes_to_pil(file_bytes: bytes) -> Image.Image:
    """
    PNG/JPEG ë“± ì¼ë°˜ ì´ë¯¸ì§€ë¥¼ PIL Image(RGB)ë¡œ ë³€í™˜
    """
    img = Image.open(io.BytesIO(file_bytes))
    if img.mode != "RGB":
        img = img.convert("RGB")
    return img

# ============================================================
# 2. Grad-CAM êµ¬í˜„
# ============================================================

class GradCAM:
    """
    ê¸°ë³¸ Grad-CAM êµ¬í˜„

    ì‚¬ìš©:
        gradcam = GradCAM(model, target_layer)
        cam, target_class, target_prob, logits = gradcam(x, threshold=0.5)
    """

    def __init__(self, model: nn.Module, target_layer: nn.Module):
        self.model = model
        self.target_layer = target_layer
        self.activations: Optional[torch.Tensor] = None
        self.gradients: Optional[torch.Tensor] = None

        # forward hook
        def forward_hook(module, inputs, output):
            self.activations = output.detach()
            output.register_hook(self._save_gradients)

        self.target_layer.register_forward_hook(forward_hook)

    def _save_gradients(self, grad: torch.Tensor):
        self.gradients = grad.detach()

    def __call__(
        self,
        x: torch.Tensor,
        target_class: Optional[int] = None,
        threshold: float = 0.5,
    ) -> Tuple[np.ndarray, int, float, np.ndarray]:
        """
        x: (1, C, H, W) on DEVICE

        threshold:
            P(Pneumonia) â‰¥ threshold ì´ë©´ Pneumonia(1), ì•„ë‹ˆë©´ Normal(0)ë¡œ ë¶„ë¥˜

        return:
            cam          : (H, W) [0~1] numpy
            target_class : 0 or 1 (Normal / Pneumonia)
            target_prob  : í•´ë‹¹ í´ë˜ìŠ¤ í™•ë¥ 
            logits       : numpy array, ì›ë³¸ ëª¨ë¸ ì¶œë ¥ (shape (1,) ë˜ëŠ” (C,))
        """
        self.model.zero_grad()
        self.activations = None
        self.gradients = None

        logits = self.model(x)  # (1, C)

        # ğŸ”¹ ì¶œë ¥ì´ í•˜ë‚˜ì¸ ì´ì§„ ëª¨ë¸ (logit for "Pneumonia")
        if logits.shape[1] == 1:
            prob_pos = torch.sigmoid(logits)[0, 0]  # P(Pneumonia)

            if target_class is None:
                # âœ… ëª¨ë¸ë³„ ì„ê³„ê°’(threshold) ê¸°ì¤€ìœ¼ë¡œ Normal / Pneumonia ê²°ì •
                target_class = int((prob_pos >= threshold).item())

            # Grad-CAMì€ Pneumonia logit ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
            score = logits[0, 0]
            probs_vec = torch.stack([1 - prob_pos, prob_pos], dim=0)  # [P(Normal), P(Pneumonia)]

        else:
            # ë‹¤ì¤‘ í´ë˜ìŠ¤ ëª¨ë¸ì¼ ê²½ìš°
            probs_vec = F.softmax(logits, dim=1)[0]
            if target_class is None:
                target_class = int(torch.argmax(probs_vec).item())
            score = logits[0, target_class]

        score.backward(retain_graph=True)

        if self.activations is None or self.gradients is None:
            raise RuntimeError("Grad-CAM hookì´ ì œëŒ€ë¡œ ì‘ë™í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        act = self.activations
        grad = self.gradients

        # global average pooling â†’ ì±„ë„ë³„ weight
        weights = grad.mean(dim=(2, 3), keepdim=True)   # [1, C, 1, 1]
        cam = (weights * act).sum(dim=1, keepdim=True)  # [1, 1, H, W]
        cam = F.relu(cam)

        cam = cam - cam.min()
        if cam.max() > 0:
            cam = cam / cam.max()

        cam_np = cam.squeeze().cpu().numpy()
        target_prob = float(probs_vec[target_class].item())
        logits_np = logits.detach().cpu().numpy()[0]

        return cam_np, target_class, target_prob, logits_np

# ============================================================
# 3. ëª¨ë¸ ë¡œë”© / ì „ì²˜ë¦¬
# ============================================================

def _build_model(model_name: str) -> nn.Module:
    """
    MODEL_CONFIGì— ë§ì¶° ëª¨ë¸ ìƒì„±.
    ì²´í¬í¬ì¸íŠ¸ êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ ì¬í˜„í•˜ê¸° ìœ„í•´ out_features=1 ë¡œ ì„¤ì •.
    """
    cfg = MODEL_CONFIG[model_name]
    builder = cfg["builder"]

    model = builder(weights=None)

    # í•™ìŠµ ë‹¹ì‹œ ì¶œë ¥ì´ 1ê°œì˜€ìŒ (ì—ëŸ¬ ë©”ì„¸ì§€ë¡œ í™•ì¸ë¨) â†’ ì„±ëŠ¥ ë³´ì¡´ ìœ„í•´ ë™ì¼í•˜ê²Œ 1ë¡œ ì„¤ì •
    if isinstance(model, models.ResNet):
        in_features = model.fc.in_features
        model.fc = nn.Linear(in_features, 1)
    elif isinstance(model, models.EfficientNet):
        in_features = model.classifier[1].in_features
        model.classifier[1] = nn.Linear(in_features, 1)
    elif isinstance(model, models.DenseNet):
        in_features = model.classifier.in_features
        model.classifier = nn.Linear(in_features, 1)
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ íƒ€ì…ì…ë‹ˆë‹¤: {type(model)}")

    return model


def _load_state_dict(model: nn.Module, ckpt_path: str) -> None:
    """
    .pth ì²´í¬í¬ì¸íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ë¡œë”© (fc í¬í•¨) â†’ ì„±ëŠ¥ ë³´ì¡´.
    """
    if not os.path.exists(ckpt_path):
        raise FileNotFoundError(f"ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ckpt_path}")

    try:
        ckpt = torch.load(ckpt_path, map_location=DEVICE, weights_only=False)
    except TypeError:
        ckpt = torch.load(ckpt_path, map_location=DEVICE)

    if isinstance(ckpt, dict) and "model_state_dict" in ckpt:
        state_dict = ckpt["model_state_dict"]
    elif isinstance(ckpt, dict) and "state_dict" in ckpt:
        state_dict = ckpt["state_dict"]
    else:
        state_dict = ckpt  # ìˆœìˆ˜ state_dict ê°€ì •

    # ì„±ëŠ¥ ë³´ì¡´ì„ ìœ„í•´ strict=True ë¡œ ì „ì²´ ë¡œë”©
    model.load_state_dict(state_dict)

# ê°„ë‹¨ ìºì‹±
_LOADED_MODELS: Dict[str, Dict[str, Any]] = {}


def get_model_bundle(model_name: str) -> Dict[str, Any]:
    """
    ëª¨ë¸ / target_layer / transform ì„ ë¡œë“œí•´ì„œ ìºì‹± í›„ ë°˜í™˜
    """
    if model_name in _LOADED_MODELS:
        return _LOADED_MODELS[model_name]

    if model_name not in MODEL_CONFIG:
        raise KeyError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ ì´ë¦„ì…ë‹ˆë‹¤: {model_name}")

    cfg = MODEL_CONFIG[model_name]
    ckpt_path = cfg["checkpoint"]
    target_layer_name = cfg["target_layer"]
    input_size = cfg["input_size"]

    model = _build_model(model_name)
    _load_state_dict(model, ckpt_path)
    model.to(DEVICE)
    model.eval()

    named_modules = dict(model.named_modules())
    if target_layer_name not in named_modules:
        raise ValueError(
            f"target_layer '{target_layer_name}' ë¥¼ model.named_modules() ë‚´ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )
    target_layer = named_modules[target_layer_name]

    transform = transforms.Compose([
        transforms.Resize((input_size, input_size)),
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225],
        ),
    ])

    bundle = {
        "model": model,
        "target_layer": target_layer,
        "transform": transform,
    }
    _LOADED_MODELS[model_name] = bundle
    return bundle


def preprocess_pil(img: Image.Image, transform: transforms.Compose) -> torch.Tensor:
    """
    PIL â†’ (1, C, H, W) Tensor on DEVICE
    """
    x = transform(img)
    x = x.unsqueeze(0)
    return x.to(DEVICE)


def apply_colormap_on_image(
    gray_cam: np.ndarray,
    rgb_img: np.ndarray,
    alpha: float = 0.4,
) -> Tuple[np.ndarray, np.ndarray]:
    """
    Grad-CAM ê²°ê³¼(gray) + ì›ë³¸ RGB â†’ heatmap / overlay
    """
    h, w, _ = rgb_img.shape
    cam_resized = cv2.resize(gray_cam, (w, h))

    heatmap_uint8 = np.uint8(255 * cam_resized)
    heatmap_bgr = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)
    heatmap_rgb = cv2.cvtColor(heatmap_bgr, cv2.COLOR_BGR2RGB)

    overlay = (heatmap_rgb * alpha + rgb_img * (1 - alpha)).astype(np.uint8)
    return heatmap_rgb, overlay

# ============================================================
# 4. ì™¸ë¶€ì—ì„œ í˜¸ì¶œí•  í•¨ìˆ˜
# ============================================================

def run_gradcam_on_pil(
    model_name: str,
    pil_img: Image.Image,
    alpha: float = 0.4,
    target_class: Optional[int] = None,
) -> Dict[str, Any]:
    """
    ë‹¨ì¼ ëª¨ë¸ì— ëŒ€í•´ Grad-CAM ì‹¤í–‰
    """
    bundle = get_model_bundle(model_name)
    model = bundle["model"]
    target_layer = bundle["target_layer"]
    transform = bundle["transform"]

    gradcam = GradCAM(model, target_layer)
    x = preprocess_pil(pil_img, transform)

    # âœ… í•™ìŠµ ì‹œ ê³„ì‚°í•œ best_threshold ì‚¬ìš©
    best_th = get_best_threshold(model_name)
    cam, t_cls, t_prob, logits = gradcam(x, target_class=target_class, threshold=best_th)

    rgb = np.array(pil_img)
    heatmap_rgb, overlay_rgb = apply_colormap_on_image(cam, rgb, alpha=alpha)

    return {
        "model_name": model_name,
        "cam": cam,
        "heatmap": heatmap_rgb,
        "overlay": overlay_rgb,
        "target_class": t_cls,
        "target_prob": t_prob,
        "logits": logits,
    }


def run_gradcam_on_file_bytes(
    model_name: str,
    file_bytes: bytes,
    alpha: float = 0.4,
    is_dicom: Optional[bool] = None,
) -> Dict[str, Any]:
    """
    íŒŒì¼ ë°”ì´íŠ¸(DICOM or ì¼ë°˜ ì´ë¯¸ì§€)ì— ëŒ€í•´ Grad-CAM ì‹¤í–‰
    """
    if is_dicom:
        pil_img, dcm = dicom_to_pil(file_bytes)
    else:
        pil_img = image_bytes_to_pil(file_bytes)
        dcm = None

    result = run_gradcam_on_pil(model_name, pil_img, alpha=alpha)
    result["pil_image"] = pil_img
    result["dicom_meta"] = dcm
    return result


def run_gradcam_all_models_on_pil(
    pil_img: Image.Image,
    alpha: float = 0.4,
) -> List[Dict[str, Any]]:
    """
    3ê°œ ëª¨ë¸(ResNet18 / EfficientNet-B0 / DenseNet121)ì— ëŒ€í•´ í•œ ë²ˆì— Grad-CAM ì‹¤í–‰
    """
    results: List[Dict[str, Any]] = []
    for m in MODEL_CONFIG.keys():
        results.append(run_gradcam_on_pil(m, pil_img, alpha=alpha))
    return results
