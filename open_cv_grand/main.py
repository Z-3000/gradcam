import io
import os
from typing import Tuple, Dict, List

import streamlit as st
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models, transforms

import numpy as np
import cv2
from PIL import Image
import pydicom

# ============================================================
# 0. ê¸°ë³¸ ì„¤ì •
# ============================================================
st.set_page_config(
    page_title="X-ray Grad-CAM Explorer",
    layout="wide",
    initial_sidebar_state="expanded"
)

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ì´ì§„ ë¶„ë¥˜ ê°€ì •: 0 = Normal, 1 = Pneumonia
NUM_CLASSES = 2
CLASS_NAMES = ["Normal", "Pneumonia"]

# ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ (ì‹¤ì œ íŒŒì¼ëª… ê¸°ì¤€)
MODEL_CONFIG: Dict[str, Dict] = {
    "ResNet18": {
        "builder": models.resnet18,
        "checkpoint": "checkpoints/251115_resnet18_NP.pth",
        "target_layer": "layer4",
        "input_size": 224,
    },
    "EfficientNet-B0": {
        "builder": models.efficientnet_b0,
        "checkpoint": "checkpoints/251115_efficientnet_NP.pth",
        "target_layer": "features",
        "input_size": 224,
    },
    "DenseNet121": {
        "builder": models.densenet121,
        "checkpoint": "checkpoints/251115_densenet121_NP.pth",
        "target_layer": "features",
        "input_size": 224,
    },
}

# âœ… Phase0 training_results ê¸°ì¤€ best_threshold
BEST_THRESHOLDS: Dict[str, float] = {
    "ResNet18": 0.25,
    "EfficientNet-B0": 0.15,
    "DenseNet121": 0.18,
}


def get_best_threshold(model_name: str) -> float:
    """ëª¨ë¸ë³„ best_threshold ë°˜í™˜, ì—†ìœ¼ë©´ 0.5 ì‚¬ìš©"""
    return BEST_THRESHOLDS.get(model_name, 0.5)

# ============================================================
# 1. ë‹¤í¬ + ê·¸ë ˆì´ìŠ¤ì¼€ì¼(X-ray ëŠë‚Œ) ì»¤ìŠ¤í…€ CSS
# ============================================================
DARK_CSS = """
<style>
:root {
    --bg-main: #050608;
    --bg-panel: #14161A;
    --bg-panel-soft: #1E2228;
    --accent: #4FD1C5;
    --accent-soft: #2C7A7B;
    --text-main: #E5E7EB;
    --text-muted: #9CA3AF;
    --border-subtle: #2D333B;
}
/* ì „ì²´ ì•± ë°°ê²½ */
.stApp {
    background: radial-gradient(circle at top, #1C1F26 0, #050608 55%) !important;
    color: var(--text-main) !important;
}
/* ê¸°ë³¸ í…ìŠ¤íŠ¸ ìƒ‰ */
body, p, span, li {
    color: var(--text-main) !important;
}
/* í—¤ë”/íƒ€ì´í‹€ */
h1, h2, h3 {
    color: #F9FAFB !important;
    font-weight: 600 !important;
}
/* ì‚¬ì´ë“œë°” */
section[data-testid="stSidebar"] {
    background-color: #050608 !important;
    border-right: 1px solid var(--border-subtle) !important;
}
section[data-testid="stSidebar"] * {
    color: var(--text-main) !important;
}
/* ì‚¬ì´ë“œë°” ì•ˆì˜ ì¹´ë“œ/ì»¨í…Œì´ë„ˆ ëŠë‚Œ */
.block-container {
    padding-top: 1.5rem !important;
}
/* íŒŒì¼ ì—…ë¡œë” */
section[data-testid="stSidebar"] .stFileUploader > div:first-child {
    background-color: var(--bg-panel) !important;
    border-radius: 10px !important;
    border: 1px dashed var(--border-subtle) !important;
    padding: 10px !important;
}
section[data-testid="stSidebar"] .stFileUploader * {
    background-color: transparent !important;
    color: var(--text-main) !important;
}
/* ë²„íŠ¼ (í˜„ì¬ ì‚¬ìš© ì•ˆ í•˜ì§€ë§Œ ìŠ¤íƒ€ì¼ ìœ ì§€) */
.stButton > button {
    background-color: var(--accent-soft) !important;
    color: #F9FAFB !important;
    border-radius: 999px !important;
    border: 1px solid var(--accent) !important;
    padding: 0.4rem 1.4rem !important;
    font-weight: 600 !important;
}
.stButton > button:hover {
    background-color: var(--accent) !important;
}
/* ë¼ë””ì˜¤/ì…€ë ‰íŠ¸ë°•ìŠ¤ ë¼ë²¨ ìƒ‰ */
.stRadio label, .stSelectbox label {
    color: var(--text-muted) !important;
    font-size: 0.9rem !important;
}
/* ìŠ¬ë¼ì´ë” */
[data-testid="stSlider"] > div {
    padding-top: 5px !important;
}
[data-baseweb="slider"] > div > div {
    background-color: #374151 !important;
}
[data-baseweb="slider"] > div > div > div {
    background-color: var(--accent) !important;
}
[data-baseweb="slider"] [role="slider"] {
    background-color: var(--accent) !important;
    border: 2px solid #F9FAFB !important;
}
/* íƒ­ ì»¨í…Œì´ë„ˆ: ë°°ê²½/ë¼ì¸ ì œê±°, í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ ìƒíƒœ êµ¬ë¶„ */
.stTabs [data-baseweb="tab-list"] {
    border-radius: 0 !important;
    background-color: transparent !important;
    padding: 0 !important;
    border: none !important;
    box-shadow: none !important;
}
/* íƒ­ ë²„íŠ¼ ê¸°ë³¸ ìŠ¤íƒ€ì¼: ì•Œì•½/ë°•ìŠ¤ ì œê±° */
.stTabs [data-baseweb="tab-list"] button {
    border-radius: 0 !important;
    background-color: transparent !important;
    box-shadow: none !important;
    border: none !important;
    padding: 0.4rem 0.9rem !important;
}
/* íƒ­ í•˜ë‹¨ ë°‘ì¤„ ì œê±° */
.stTabs [data-baseweb="tab"] {
    border-bottom: none !important;
    background-color: transparent !important;
}
/* í™œì„± íƒ­: ë°ì€ ê¸€ì + ì‚´ì§ ë‘ê»˜ */
.stTabs [data-baseweb="tab-list"] button[aria-selected="true"] {
    background-color: transparent !important;
    color: #F9FAFB !important;
    font-weight: 600 !important;
}
/* ë¹„í™œì„± íƒ­: íë¦° ê¸€ì */
.stTabs [data-baseweb="tab-list"] button[aria-selected="false"] {
    background-color: transparent !important;
    color: var(--text-muted) !important;
    font-weight: 400 !important;
}
/* ì´ë¯¸ì§€ ì£¼ë³€ íŒ¨ë„ â€“ ë°°ê²½/í…Œë‘ë¦¬ ì œê±°í•´ì„œ ë¹ˆ ë°•ìŠ¤ ì—†ì• ê¸° */
.xray-panel {
    padding: 0;
    margin: 0 0 6px 0;
    border: none;
    background: transparent;
}
/* íŒ¨ë„ ì œëª©ë§Œ ì‹¬í”Œí•˜ê²Œ ë‚¨ê¸°ê¸° */
.xray-panel-title {
    font-size: 0.9rem;
    font-weight: 600;
    color: var(--text-muted);
    text-transform: uppercase;
    letter-spacing: 0.08em;
    margin-bottom: 4px;
}
/* í•˜ë‹¨ ì„¤ëª… ì¹´ë“œ */
.info-card {
    background-color: var(--bg-panel-soft);
    border-radius: 12px;
    border: 1px solid var(--border-subtle);
    padding: 10px 12px;
}
/* ë°ì´í„°í”„ë ˆì„/í…Œì´ë¸” */
.dataframe {
    background-color: var(--bg-panel) !important;
}
/* ì•Œë¦¼/ê²½ê³  ë°•ìŠ¤ */
.stAlert {
    background-color: rgba(55, 65, 81, 0.6) !important;
    border-radius: 10px !important;
    border: 1px solid var(--border-subtle) !important;
}
/* ì‘ì€ ë±ƒì§€ ìŠ¤íƒ€ì¼ */
.badge-pill {
    display: inline-block;
    padding: 2px 10px;
    border-radius: 999px;
    font-size: 0.75rem;
    border: 1px solid var(--border-subtle);
    color: var(--text-muted);
}
/* Grad-CAM íŠ¸ë¦¬ê±° ì¹´ë“œ (ì‚¬ìš© ì•ˆ í•´ë„ ìŠ¤íƒ€ì¼ ìœ ì§€ ê°€ëŠ¥) */
.gradcam-trigger-box {
    margin-top: 0rem;
    margin-bottom: 0.75rem;
    padding: 10px 12px;
    border-radius: 12px;
    border: 1px solid var(--border-subtle);
    background-color: #111827;
}
.gradcam-trigger-title {
    font-size: 0.85rem;
    font-weight: 600;
    color: var(--text-main);
    margin-bottom: 4px;
}
.gradcam-trigger-desc {
    font-size: 0.78rem;
    color: var(--text-muted);
    margin: 0;
}
/* í™•ë¥  ë°” */
.prob-bar-bg {
    background-color: #111827;
    border-radius: 999px;
    height: 8px;
    width: 100%;
}
.prob-bar-fill {
    background: linear-gradient(90deg, var(--accent), #FBBF24);
    border-radius: 999px;
    height: 8px;
}
/* ì œëª© ì„¹ì…˜ ì—¬ë°± ë° í¬ê¸° ì¡°ì • */
h3 {
    font-size: 1.35rem !important;
    margin-top: 1.2rem !important;
    margin-bottom: 0.6rem !important;
}
/* í˜ì´ì§€ ìƒë‹¨ ì „ì²´ íŒ¨ë”© */
.block-container {
    padding-top: 2.5rem !important;
}
</style>
"""
st.markdown(DARK_CSS, unsafe_allow_html=True)

# ============================================================
# 2. DICOM / ì´ë¯¸ì§€ ë¡œë”© ìœ í‹¸
# ============================================================

def load_dicom_as_pil(file_bytes: bytes) -> Tuple[Image.Image, pydicom.Dataset]:
    """
    DICOM ë°”ì´íŠ¸ â†’ (PIL Image, DICOM Dataset)
    í•™ìŠµ ì‹œ ì‚¬ìš©í•œ dicom_to_pngì™€ ë™ì¼í•œ ë°©ì‹:
    - HU ë³€í™˜ (RescaleSlope/Intercept)
    - Lung window (center=40, width=800)
    """
    ds = pydicom.dcmread(io.BytesIO(file_bytes))
    img = ds.pixel_array.astype(np.float32)

    # HU ë³€í™˜
    if hasattr(ds, "RescaleSlope") and hasattr(ds, "RescaleIntercept"):
        slope = float(ds.RescaleSlope)
        intercept = float(ds.RescaleIntercept)
        img = img * slope + intercept

    # Lung window ì ìš©
    window_center = 40.0
    window_width = 800.0
    min_val = window_center - window_width / 2.0
    max_val = window_center + window_width / 2.0

    img = (img - min_val) / (max_val - min_val)
    img = np.clip(img, 0.0, 1.0)
    img = (img * 255.0).astype(np.uint8)

    pil_img = Image.fromarray(img).convert("RGB")
    return pil_img, ds


def load_generic_image_as_pil(file_bytes: bytes) -> Image.Image:
    """PNG/JPEG â†’ PIL(RGB)"""
    img = Image.open(io.BytesIO(file_bytes))
    if img.mode != "RGB":
        img = img.convert("RGB")
    return img

# ============================================================
# 3. Grad-CAM í•µì‹¬ í´ë˜ìŠ¤
# ============================================================

class GradCAM:
    def __init__(self, model: nn.Module, target_layer: nn.Module):
        self.model = model
        self.target_layer = target_layer
        self.activations = None
        self.gradients = None

        def forward_hook(module, inp, out):
            self.activations = out.detach()
            out.register_hook(self._save_gradients)

        self.target_layer.register_forward_hook(forward_hook)

    def _save_gradients(self, grad):
        self.gradients = grad.detach()

    def __call__(
        self,
        x: torch.Tensor,
        target_class: int = None,
        threshold: float = 0.5,
    ) -> Tuple[np.ndarray, int, float, np.ndarray]:
        """
        x: (1, C, H, W)
        threshold:
            P(Pneumonia) â‰¥ threshold â†’ Pneumonia(1), else Normal(0)
        return:
            cam: (H, W) 0~1 float
            target_class: 0/1
            target_prob: float (ì„ íƒëœ í´ë˜ìŠ¤ì˜ í™•ë¥ )
            logits: numpy array
        """
        self.model.zero_grad()
        self.activations = None
        self.gradients = None

        logits = self.model(x)  # (1, C)

        # ì´ì§„ ëª¨ë¸ (logit for Pneumonia)
        if logits.shape[1] == 1:
            prob_pos = torch.sigmoid(logits)[0, 0]  # P(Pneumonia)

            if target_class is None:
                target_class = int((prob_pos >= threshold).item())

            score = logits[0, 0]
            probs_vec = torch.stack([1 - prob_pos, prob_pos], dim=0)

        else:
            # ë‹¤ì¤‘ í´ë˜ìŠ¤ ëŒ€ë¹„
            probs_vec = F.softmax(logits, dim=1)[0]
            if target_class is None:
                target_class = int(torch.argmax(probs_vec).item())
            score = logits[0, target_class]

        score.backward(retain_graph=True)

        if self.activations is None or self.gradients is None:
            raise RuntimeError("Grad-CAM hookì´ ì œëŒ€ë¡œ ë“±ë¡ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        act = self.activations
        grad = self.gradients

        weights = grad.mean(dim=(2, 3), keepdim=True)
        cam = (weights * act).sum(dim=1, keepdim=True)
        cam = F.relu(cam)

        cam = cam - cam.min()
        if cam.max() > 0:
            cam = cam / cam.max()

        cam_np = cam.squeeze().cpu().numpy()
        target_prob = float(probs_vec[target_class].item())
        logits_np = logits.detach().cpu().numpy()[0]

        return cam_np, target_class, target_prob, logits_np

# ============================================================
# 4. ëª¨ë¸ ë¡œë”©/ì „ì²˜ë¦¬
# ============================================================

@st.cache_resource
def load_model(model_name: str) -> Tuple[nn.Module, nn.Module, transforms.Compose]:
    """
    ëª¨ë¸ ë¡œë“œ + target_layer ì°¾ê¸° + transform ë°˜í™˜
    - ì„±ëŠ¥ ë³´ì¡´ì„ ìœ„í•´ checkpoint êµ¬ì¡°(out_features=1)ì— ë§ì¶° ëª¨ë¸ ìƒì„±
    """
    cfg = MODEL_CONFIG[model_name]
    builder = cfg["builder"]
    target_layer_name = cfg["target_layer"]
    input_size = cfg["input_size"]

    model = builder(weights=None)

    # í•™ìŠµ ë‹¹ì‹œ fc ì¶œë ¥ ì°¨ì› = 1 â†’ ë™ì¼í•˜ê²Œ ë§ì¶¤
    if isinstance(model, models.ResNet):
        in_features = model.fc.in_features
        model.fc = nn.Linear(in_features, 1)
    elif isinstance(model, models.EfficientNet):
        in_features = model.classifier[1].in_features
        model.classifier[1] = nn.Linear(in_features, 1)
    elif isinstance(model, models.DenseNet):
        in_features = model.classifier.in_features
        model.classifier = nn.Linear(in_features, 1)
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ íƒ€ì…: {type(model)}")

    ckpt_path = cfg["checkpoint"]
    if not os.path.exists(ckpt_path):
        raise FileNotFoundError(
            f"ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ckpt_path}\n"
            f"MODEL_CONFIGì—ì„œ ê²½ë¡œë¥¼ ì‹¤ì œ .pth íŒŒì¼ ìœ„ì¹˜ë¡œ ìˆ˜ì •í•˜ì„¸ìš”."
        )

    # PyTorch 2.6: weights_only ê¸°ë³¸ê°’ True â†’ ì˜ˆì „ ì²´í¬í¬ì¸íŠ¸ ëŒ€ì‘
    try:
        ckpt = torch.load(ckpt_path, map_location=DEVICE, weights_only=False)
    except TypeError:
        ckpt = torch.load(ckpt_path, map_location=DEVICE)

    if isinstance(ckpt, dict) and "model_state_dict" in ckpt:
        state_dict = ckpt["model_state_dict"]
    elif isinstance(ckpt, dict) and "state_dict" in ckpt:
        state_dict = ckpt["state_dict"]
    else:
        state_dict = ckpt

    # ì„±ëŠ¥ ë³´ì¡´ì„ ìœ„í•´ strict ë¡œ ì „ì²´ ë¡œë”©
    model.load_state_dict(state_dict)

    model.to(DEVICE)
    model.eval()

    named_modules = dict(model.named_modules())
    if target_layer_name not in named_modules:
        raise ValueError(
            f"target_layer '{target_layer_name}' ë¥¼ model.named_modules()ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )
    target_layer = named_modules[target_layer_name]

    transform = transforms.Compose([
        transforms.Resize((input_size, input_size)),
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225],
        ),
    ])

    return model, target_layer, transform


def preprocess_for_model(img: Image.Image, transform: transforms.Compose) -> torch.Tensor:
    x = transform(img)
    x = x.unsqueeze(0)
    return x.to(DEVICE)


def apply_colormap_on_image(
    gray_cam: np.ndarray,
    rgb_img: np.ndarray,
    alpha: float = 0.4,
) -> Tuple[np.ndarray, np.ndarray]:
    """
    gray_cam: (H, W) 0~1
    rgb_img: (H, W, 3) uint8
    """
    h, w, _ = rgb_img.shape
    cam_resized = cv2.resize(gray_cam, (w, h))

    heatmap_uint8 = np.uint8(255 * cam_resized)
    heatmap_bgr = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)
    heatmap_rgb = cv2.cvtColor(heatmap_bgr, cv2.COLOR_BGR2RGB)

    overlay = (heatmap_rgb * alpha + rgb_img * (1 - alpha)).astype(np.uint8)
    return heatmap_rgb, overlay

# ============================================================
# 5. ìƒë‹¨ ì„¤ëª…
# ============================================================

st.markdown(
    """
    ### X-ray Grad-CAM Explorer
    
    ë”¥ëŸ¬ë‹ ëª¨ë¸(ResNet18 / EfficientNet-B0 / DenseNet121)ì˜ **íë ´ ë¶„ë¥˜ ê²°ê³¼ì™€ Grad-CAM ì‹œê°í™”**ë¥¼ í•œ í™”ë©´ì—ì„œ í™•ì¸í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.  
    """,
    unsafe_allow_html=False,
)

st.markdown("<div class='badge-pill'>Experimental Â· RSNA Pneumonia (Assumed)</div>", unsafe_allow_html=True)
st.markdown("---")

# ============================================================
# 6. ì‚¬ì´ë“œë°” (ì—…ë¡œë“œ + ì˜µì…˜)
# ============================================================

st.sidebar.header("ì…ë ¥ ì´ë¯¸ì§€ ì—…ë¡œë“œ")

uploaded_file = st.sidebar.file_uploader(
    "",
    type=["dcm", "png", "jpg", "jpeg"],
)

st.sidebar.markdown("---")
st.sidebar.header("Grad-CAM Options")

view_mode = st.sidebar.radio(
    "View Mode",
    ["ë‹¨ì¼ ëª¨ë¸", "3ê°œ ëª¨ë¸ ë¹„êµ"],
)

model_name = st.sidebar.selectbox(
    "Model Selection",
    list(MODEL_CONFIG.keys()),
    index=0,
)

alpha = st.sidebar.slider(
    "Heatmap Overlay Alpha",
    min_value=0.1, max_value=0.9, value=0.45, step=0.05
)

# ============================================================
# 7. Grad-CAM ì‹¤í–‰ í•¨ìˆ˜
# ============================================================

def run_gradcam_for_model(
    model_label: str,
    base_img: Image.Image,
    alpha: float,
) -> Dict:
    model, target_layer, transform = load_model(model_label)
    gradcam = GradCAM(model, target_layer)

    x = preprocess_for_model(base_img, transform)

    # âœ… ëª¨ë¸ë³„ best_threshold ì ìš©
    best_th = get_best_threshold(model_label)
    cam, target_class, target_prob, logits = gradcam(
        x,
        target_class=None,
        threshold=best_th,
    )

    rgb = np.array(base_img)
    heatmap_rgb, overlay_rgb = apply_colormap_on_image(cam, rgb, alpha=alpha)

    return {
        "model_name": model_label,
        "cam": cam,
        "heatmap": heatmap_rgb,
        "overlay": overlay_rgb,
        "target_class": target_class,
        "target_prob": target_prob,
        "logits": logits,
    }

# ============================================================
# 8. ë©”ì¸ ë¡œì§
# ============================================================

if uploaded_file is None:
    st.info("ì¢Œì¸¡ì—ì„œ DICOM ë˜ëŠ” X-ray ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ Grad-CAMì´ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.")
else:
    # íŒŒì¼ ë¡œë“œ
    file_bytes = uploaded_file.read()
    filename = uploaded_file.name.lower()

    if filename.endswith(".dcm"):
        base_img, dcm_ds = load_dicom_as_pil(file_bytes)
        dicom_mode = True
    else:
        base_img = load_generic_image_as_pil(file_bytes)
        dcm_ds = None
        dicom_mode = False

    # íƒ­ êµ¬ì„±
    tab_viz, tab_pred, tab_meta = st.tabs(
        ["ğŸ–¼ Grad-CAM ì‹œê°í™”", "ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼", "â„¹ ë©”íƒ€ë°ì´í„°"]
    )

    # -----------------------------
    # íƒ­ 1: Grad-CAM ì‹œê°í™”
    # -----------------------------
    with tab_viz:
        if view_mode == "ë‹¨ì¼ ëª¨ë¸":
            with st.spinner(f"{model_name} Grad-CAM ê³„ì‚° ì¤‘..."):
                result = run_gradcam_for_model(model_name, base_img, alpha)

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("<div class='xray-panel'>", unsafe_allow_html=True)
                st.markdown("<div class='xray-panel-title'>Original</div>", unsafe_allow_html=True)
                st.image(base_img, use_container_width=True, clamp=True)
                st.markdown("</div>", unsafe_allow_html=True)

            with col2:
                st.markdown("<div class='xray-panel'>", unsafe_allow_html=True)
                st.markdown("<div class='xray-panel-title'>Overlay</div>", unsafe_allow_html=True)
                st.image(result["overlay"], use_container_width=True, clamp=True)
                st.markdown("</div>", unsafe_allow_html=True)

            st.markdown(
                f"<div class='info-card'>"
                f"<b>{model_name}</b> Â· Predicted: <b>{CLASS_NAMES[result['target_class']]}</b> "
                f"(p = {result['target_prob']:.3f})"
                f"</div>",
                unsafe_allow_html=True,
            )

        else:  # 3ê°œ ëª¨ë¸ ë¹„êµ
            cols = st.columns(3)
            results: List[Dict] = []

            with st.spinner("3ê°œ ëª¨ë¸ì— ëŒ€í•´ Grad-CAM ê³„ì‚° ì¤‘..."):
                for m in MODEL_CONFIG.keys():
                    results.append(run_gradcam_for_model(m, base_img, alpha))

            for col, res in zip(cols, results):
                with col:
                    st.markdown("<div class='xray-panel'>", unsafe_allow_html=True)
                    st.markdown(
                        f"<div class='xray-panel-title'>{res['model_name']} Â· Overlay</div>",
                        unsafe_allow_html=True,
                    )
                    st.image(res["overlay"], use_container_width=True, clamp=True)
                    st.markdown("</div>", unsafe_allow_html=True)

                    st.markdown(
                        f"<div class='info-card'><b>{res['model_name']}</b><br>"
                        f"Pred: <b>{CLASS_NAMES[res['target_class']]}</b> "
                        f"(p = {res['target_prob']:.3f})"
                        f"</div>",
                        unsafe_allow_html=True,
                    )

    # -----------------------------
    # íƒ­ 2: ì˜ˆì¸¡ ê²°ê³¼
    # -----------------------------
    with tab_pred:
        if view_mode == "ë‹¨ì¼ ëª¨ë¸":
            res = run_gradcam_for_model(model_name, base_img, alpha)
            st.subheader(f"{model_name} Â· í´ë˜ìŠ¤ í™•ë¥ ")

            logits = torch.from_numpy(res["logits"])
            if logits.numel() == 1:
                prob_pos = torch.sigmoid(logits)[0].item()
                probs = np.array([1 - prob_pos, prob_pos])  # [Normal, Pneumonia]
            else:
                probs = F.softmax(logits, dim=0).numpy()

            for idx, cls in enumerate(CLASS_NAMES):
                with st.container():
                    st.write(f"{cls}: {probs[idx]:.3f}")
                    st.markdown(
                        "<div class='prob-bar-bg'>"
                        f"<div class='prob-bar-fill' style='width: {probs[idx]*100:.1f}%;'></div>"
                        "</div>",
                        unsafe_allow_html=True,
                    )
        else:
            st.subheader("3ê°œ ëª¨ë¸ í´ë˜ìŠ¤ í™•ë¥  ë¹„êµ")
            for m in MODEL_CONFIG.keys():
                res = run_gradcam_for_model(m, base_img, alpha)
                st.markdown(f"#### {m}")

                logits = torch.from_numpy(res["logits"])
                if logits.numel() == 1:
                    prob_pos = torch.sigmoid(logits)[0].item()
                    probs = np.array([1 - prob_pos, prob_pos])
                else:
                    probs = F.softmax(logits, dim=0).numpy()

                for idx, cls in enumerate(CLASS_NAMES):
                    with st.container():
                        st.write(f"{cls}: {probs[idx]:.3f}")
                        st.markdown(
                            "<div class='prob-bar-bg'>"
                            f"<div class='prob-bar-fill' style='width: {probs[idx]*100:.1f}%;'></div>"
                            "</div>",
                            unsafe_allow_html=True,
                        )
                st.markdown("---")

    # -----------------------------
    # íƒ­ 3: ë©”íƒ€ë°ì´í„°
    # -----------------------------
    with tab_meta:
        st.subheader("ì…ë ¥ ì´ë¯¸ì§€ ì •ë³´")

        cols_info = st.columns(2)
        with cols_info[0]:
            st.write(f"íŒŒì¼ëª…: `{uploaded_file.name}`")
            st.write(f"í˜•ì‹: {'DICOM' if dicom_mode else 'ì¼ë°˜ ì´ë¯¸ì§€'}")
            st.write(f"ì›ë³¸ í¬ê¸°: {base_img.size[0]} x {base_img.size[1]}")

        if dicom_mode and dcm_ds is not None:
            with cols_info[1]:
                wc = dcm_ds.get("WindowCenter", "N/A")
                ww = dcm_ds.get("WindowWidth", "N/A")
                st.write(f"Window Center: {wc}")
                st.write(f"Window Width: {ww}")
                st.write(f"Modality: {dcm_ds.get('Modality', 'N/A')}")
        else:
            with cols_info[1]:
                st.write("DICOM ë©”íƒ€ë°ì´í„°ëŠ” ì œê³µë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
